Loci Subsampling - Selecting Loci that support known clades
Analysis notes

GitHub Repo:
https://github.com/LMBiancani/FilterByKnownClades

Written Notes:
https://docs.google.com/document/d/1JuyuBTQ92Tx13pbG4MbDrLy_Qv37Juk4LdzJcGbz2Qw/edit?usp=sharing

Andromeda location:
cd /data/schwartzlab/Biancani/FilterByKnownClades/

Local location:
cd /Users/biancani/Documents/FilterByKnownClades

Alexandra Machine Learning Repo (for simulated loci):
https://github.com/alexandrawalling/PML/tree/main

Local (macbook) directory:
/Users/biancani/Documents/FilterByKnownClades
Andromeda directory:
/data/schwartzlab/Biancani/FilterByKnownClades

2024.05.29

Goal: convert a forked repo to a stand-alone repository without loosing any of the tracked history or contributions.
Create stand-alone repository from Zack's github.

- Fork Zack's Repository: https://github.com/LMBiancani/FilterByKnownClades

Locally:
- Pull all changes in Forked repo to local machine
git clone https://github.com/LMBiancani/FilterByKnownClades

On Github:
- Change the name of the Forked Repository (to anything else ex. "DeleteMe")
- Create a new, empty repo and give it the original name of the Forked Repository

Locally:
- Push all changes to Github (you should not have to do anything special because the new repo now has the same name as
the repo this was originally synced with).
On Github:
- Confirm the new repository contains everything it should
- Delete the forked repository

On Andromeda:
git clone https://github.com/LMBiancani/FilterByKnownClades

add gitignore and include Loci folder

Subset Zack's aligned loci to create test dataset:
/data/schwartzlab/zbergeron/SISRS_mammals/filteredMammalLoci
(101,405 alignments)
ls *11.fasta
(2,780 alignement)

cp /data/schwartzlab/zbergeron/SISRS_mammals/filteredMammalLoci/*11.fasta /data/schwartzlab/Biancani/FilterByKnownClades/Loci/

2024.06.27
Simulations from Alexandra
Simulated loci:
/data/schwartzlab/awalling/Phylo_ML/simulations/empirical/fong/1/alignments3/
/data/schwartzlab/awalling/Phylo_ML/simulations/empirical/liu/1/alignments3/
/data/schwartzlab/awalling/Phylo_ML/simulations/empirical/mcgowen/1/alignments3/
/data/schwartzlab/awalling/Phylo_ML/simulations/empirical/wickett/1/alignments3/

Use copy_data.sh to copy simulated loci to Loci folder (on andromeda only: Data folder listed in gitignore)
deistination folders:
/data/schwartzlab/Biancani/FilterByKnownClades/data/Fong/simulated_loci/
/data/schwartzlab/Biancani/FilterByKnownClades/data/Liu/simulated_loci/
/data/schwartzlab/Biancani/FilterByKnownClades/data/McGowen/simulated_loci/
/data/schwartzlab/Biancani/FilterByKnownClades/data/Wickett/simulated_loci/

tree used for simulations: inferenceEmpirical.iqtree
submission file that generated Empirical trees:
run_iqtree_Fong_empirical.sh
run_iqtree_..._empirical.sh
in...
/data/schwartzlab/awalling/Phylo_ML/datasets/Fong_alignments/
/data/schwartzlab/awalling/Phylo_ML/datasets/Liu_alignments/
/data/schwartzlab/awalling/Phylo_ML/datasets/McGowen_alignments/
/data/schwartzlab/awalling/Phylo_ML/datasets/Wickett_alignments/

Example submission file for generating emperical trees:
run_iqtree_Fong_empirical.sh
----------
#!/bin/bash
#SBATCH --job-name="IQFong"
#SBATCH --time=96:00:00  # walltime limit (HH:MM:SS)
#SBATCH --nodes=2   # number of nodes
#SBATCH --ntasks-per-node=24   # processor core(s) per node
#SBATCH --mem=250G
#SBATCH --exclusive


cd $SLURM_SUBMIT_DIR

date
#Path to IQTREE executable. Modify with path to your own executable.
iqtree_exe="/home/aknyshov/alex_data/andromeda_tools/iqtree-2.1.2-Linux/bin/iqtree2"


#Concatenate input fasta files and prepare partitions ahead of IQTree run
python3 /home/aknyshov/alex_data/andromeda_tools/AMAS/amas/AMAS.py concat -f fasta -d dna --out-format fasta --part-format raxml -i *fas -c 20 -t concatenatedTrain.fasta -p partitionsTrain.txt

#Run IQtree. Flags: -nt: use 20 CPU cores -spp: specifies partition file but allows partitions to have different evolutionary speeds -pre: specifies prefix for output files -m: determine best fit model immediately followed by tree reconstruction -bb: sets 1000 bootstrap replicates  -alrt: sets 1000 replicates to perform SH-like approximate likelihood test (SH-aLRT)
${iqtree_exe} -nt 20 -s concatenatedTrain.fasta -spp partitionsTrain.txt -pre inferenceEmpirical -m MFP -bb 1000 -alrt 1000


date
---------

2024.07.03

To Do:

- For each simulated locus:
  - infer an unconstrained gene tree, calculate maximum likelihood (completed?)
  - infer a constrained gene tree (constrain "known" clade), calculate maximum likelihood
  - compare likelihoods
    - if constrained is > or = unconstrained, keep LOCUS (else filter locsus)
- Build species tree from filtered simulated Loci
- Build species tree from unfiltered simulated LOCI
- Compare species tree to empirical tree (which is more similar)?


nano /data/schwartzlab/Biancani/FilterByKnownClades/01_iqtree/01_iqtree_prep.sh
##########
#!/bin/bash
#SBATCH --job-name="IQprep"
#SBATCH --time=1:00:00  # walltime limit (HH:MM:SS)
#SBATCH --mail-user="biancani@uri.edu" #CHANGE THIS to your user email address
#SBATCH --mail-type=ALL
#SBATCH --nodes=1   # number of nodes
#SBATCH --ntasks-per-node=1   # processor core(s) per node
#SBATCH -c 1
#SBATCH --mem-per-cpu=6G

## UPDATE PATHS as needed...
# path to Project Directory:
PROJECT=/data/schwartzlab/Biancani/FilterByKnownClades
# path to IQtree scripts:
scripts_dir=$PROJECT/01_iqtree
# path to aligned loci:
aligned_loci_path=$PROJECT/Loci/Simulated/Fong/
# path to output folder (will be created if doesn't exist):
OUTPUT=$PROJECT/output
# name of iqtree array work folder (will be created if doesn't exist):
array_work_folder=iqtree_assessment


mkdir -p $OUTPUT
cd $OUTPUT
mkdir -p ${array_work_folder}
cd ${array_work_folder}
mkdir scf
ls ${aligned_loci_path} | rev | cut -f1 -d/ | rev | split - aligned_loci_list_
arrayN=$(ls aligned_loci_list_* | wc -l)
ls aligned_loci_list_* > array_list.txt
echo sbatch --array=1-${arrayN}%40 ${scripts_dir}iqtree_array.sh
##########
