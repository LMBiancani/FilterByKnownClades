---
title: "Notes"
author: "Leann M. Biancani"
output: html_document
---
[GitHub Repository: PlacentalPolytomy](https://github.com/LMBiancani/PlacentalPolytomy)

```{css backgrounds, echo=FALSE}
/* Define a background class for displaying content of slurm submission text files */
.bg_slurm {
  background-color: aliceblue;
  border: 1px solid black;
}
/* Define a background class for displaying content of python text files */
.bg_python {
  background-color: lightyellow;
  border: 1px solid black;
}
/* Define a background class for displaying content of text files */
.bg_text {
  background-color: honeydew;
  border: 1px solid black;
}
```

# 1. Filter By Taxa
Scripts are located in the [filterByTaxa](https://github.com/LMBiancani/PlacentalPolytomy/tree/main/filterByTaxa) folder.

* Removes excessively incomplete sequences (ex. sequence must be less than 33% Ns)
* Removes aligned loci with too few taxa represented (ex. locus must include sequences for at least 25 taxa)
* Removes aligned loci with incomplete clade sampling (ex. locus must include a sequence from all 4 taxon groups included in the `groups.csv` file)
* The required taxon-to-group correspondence table, `groups.csv`, is a csv file with the following format: 
```
Group,Taxa
group1,taxonName1
group1,taxonName2
group2,taxonName3
group2,taxonName4
```
### Slurm submission script: `filter_SISRS_output.sh`
* runs the following python script: `filter_SISRS_output.py`
```{bash, comment=NA, echo=FALSE, class.output="bg_slurm"}
cat filterByTaxa/filter_SISRS_output.sh
```
### Python script: `filter_SISRS_output.py`
*  run by previous shell script: `filter_SISRS_output.sh`
```{bash, comment=NA, echo=FALSE, class.output="bg_python"}
cat filterByTaxa/filter_SISRS_output.py
```
### Taxon-to-group table: `groups.csv`
* specify path to this input file in previous shell script: `filter_SISRS_output.sh`
```{bash, comment=NA, echo=FALSE, class.output="bg_text"}
cat filterByTaxa/groups.csv
```

# 2. Annotate Loci
Scripts are located in the [annotation](https://github.com/LMBiancani/PlacentalPolytomy/tree/main/annotation) folder.

* Aligns SISRS loci of a particular taxon to a reference genome (ideally, of the same taxon).
* A custom script is used to retreive a reference taxon for the loci.
* BLAST is run. 
* A custom python script is used to filter the output and convert it to BED. Overlapping hits of similar scores as well as very disjunct alignments are discarded. The BED file is then sorted and intersected with the GFF file for the reference sequence.
* A custom python script then processess the intersected BED file to produce the final output,
either counts of different annotation types, or length proportion of each annotations type. The following types of annotations are recorded: pseudogene, CDS, UTR, intron, lnc_RNA, other (any other type), unannotated (or intergenic).

### Slurm submission script: `download_reference.sh`
* downloads reference genome (FASTA) and annotation (GFF) for Pan troglodytes (chimpanzee) [GCF_002880755.1](https://www.ncbi.nlm.nih.gov/data-hub/genome/GCF_002880755.1/)
```{bash, comment=NA, echo=FALSE, class.output="bg_slurm"}
cat annotation/download_reference.sh
```
### Slurm submission script: `annotation_job.sh`
* runs the following python scripts: `annotation_getTaxContigs.py`, `annotation_blast_parser.py`, `annotation_bed2table.py`
```{bash, comment=NA, echo=FALSE, class.output="bg_slurm"}
cat annotation/annotation_job.sh
```
### Python script: `annotation_getTaxContigs.py`
* run by previous shell script: `annotation_job.sh`
* extracts SISRS loci of a particular taxon into a single file for use with BLAST
```{bash, comment=NA, echo=FALSE, class.output="bg_python"}
cat annotation/annotation_getTaxContigs.py
```
### Python script: `annotation_blast_parser.py`
* BLAST to BED python script run by the previous shell script: `annotation_job.sh`
* adjust parameters on lines 10-12 as needed
```{bash, comment=NA, echo=FALSE, class.output="bg_python"}
cat annotation/annotation_blast_parser.py
```
### Python script: `annotation_bed2table.py`
* BED to table python script run by the previous shell script: `annotation_job.sh`
* two options are provided (to be specified in shell script: `annotation_job.sh`)
1. count the number of each feature per locus (`c`), for ex. 1 CDS, 2 introns, etc.
2. compute proportion of length of each feature type per locus (`l`), for ex. 0.2 CDS, 0.8 introns
```{bash, comment=NA, echo=FALSE, class.output="bg_python"}
cat annotation/annotation_bed2table.py
```

# 3. Assess locus properties
## 3.1. AMAS
Scripts are located in the [amas](https://github.com/LMBiancani/PlacentalPolytomy/tree/main/amas) folder.

* Runs AMAS to assess locus features
* **Note:** AMAS takes file names as command line arguments with a limit on how long the line can be. In order to analyze several hundred thousand files, AMAS is run in batches by the driver script (`run_amas.py`).

### Download AMAS
* note path to `AMAS.py` and add path to slurm script `run_amas.sh`
```
git clone https://github.com/marekborowiec/AMAS/
```
### Slurm submission script: `run_amas.sh`
* runs the following python script: `run_amas.py`
```{bash, comment=NA, echo=FALSE, class.output="bg_slurm"}
cat amas/run_amas.sh
```
### Python script: `run_amas.py`
* python script run by shell script: `run_amas.sh`
```{bash, comment=NA, echo=FALSE, class.output="bg_python"}
cat amas/run_amas.py
```

# [TreeshrewProject](https://github.com/AlexKnyshov/TreeshrewProject)
Notes for Scripts associated with the Treeshrew project:

## Filter by taxa
See **filterByTaxa** folder
* filter_SISRS_output.sh - slurm script to run
* filter_SISRS_output.py - script run by the previous shell script
Loci are first filtered from incomplete sequences (for the treeshrew project each passing sequence must have over 33% non N), then are filtered by the number of taxa retained (for the treeshrew project the locus passes if 25 taxa are remaining) and then by the number of groups present (for the treeshrew project all 6 groups must be present).
The taxa to group correspondence table is expected to be a csv file and look like this:
```
group1,taxonName1
group1,taxonName2
group2,taxonName3
group2,taxonName4
```


## Locus filtering using Branch Length Correlation
This step can be used to filter out outlier loci based on discordance in branch length distribution. For use with this script a gene tree for each locus needs to be computed. See IQ-TREE analyses below, and iqtree_array_gtree.sh and iqtree_collect_gtrees.sh in particular. Output is a table with regression slope and R-squared, the latter can be used to rank and filter out loci with worst (lowest) values.
See **screening** folder
* treescreen.sh - to run the screening job
* treescreen.R - tree screening R script, run by the shell script above

## Locus annotation

This step aligns SISRS loci of a particular taxon to the reference sequence (ideally, of the same taxon). A custom script is used to retreive a reference taxon for the loci. Then BLAST is run. A custom python script is used to filter the output and convert it to BED. Overlapping hits of similar scores as well as very disjunct alignments are discarded. The BED file is then sorted and intersected with the GFF file for the reference sequence. A custom python script then processess the intersected BED file to produce the final output, either counts of different types of annotations, or length proportions of each of types of annotations. Currently the following types of annotations are recorded: pseudogene, CDS, UTR, intron, lnc_RNA, other (any other type), unannotated (or intergenic). See **annotation** folder
* annotation_job.sh - slurm script to submit; adjust file paths; adjust the command options on line 30 for the last script (see below)
* annotation_blast_parser.py - BLAST to BED script run by the previous shell script; adjust parameters on lines 10-12 as needed.
* annotation_bed2table.py - BED to table script run by the previous shell script; two options are provided: count the number of each feature per locus (`c`), for ex. 1 CDS, 2 introns, etc.; or compute proportion of length of each feature type per locus (`l`), for ex. 0.2 CDS, 0.8 introns.
* getTaxContigs.py - script to extract SISRS loci of a particular taxon into a single file for use with BLAST

## Assess locus properties

### AMAS
This step runs AMAS to assess locus features. Since AMAS takes file names as command line arguments, there's a limit on how long the line can be, and we have several hundred thousand files, AMAS is run in batches by the driver script. See **amas** folder
* run_amas.sh - slurm script to run; adjust `12` to the number of cores you wish to use
* run_amas.py - script run by the previous shell script

### Saturation
This step assesses uncorrected (raw) and corrected (TN93) pairwise distances for each locus, fits linear model to the data, and outputs the slope and R squared (modified from Borowiec et al. 2015). If the fit is good, the slope would be indicative of the degree of saturation. See **saturation** folder
* saturation.sh - slurm script to run; adjust paths to loci and to the saturation.R script.
* saturation.R - script run by the previous shell script

### Phylomad
This step runs phylomad. As phylomad has "control file" that specifies all parameters of the run, it is problematic to adjust it for each of the several hundred thousand runs needed. The solution here is to first adjust all parameters in the control file besides the filenames. Then a driver script takes care of adjusting the control file for each locus and running phylomad on it. Because phylomad is computationally intensive and we have too many alignments to run through, this step is set up as an array job. See **phylomad** folder
* phylomad_prep.sh - slurm script to set up the phylomad array; adjust the paths, possibly also the number of simultaneously run jobs on line 18 after the % sign.
* phylomad_array.sh - slurm script to run the array job; adjust the paths.
* phylomad_collect_output.sh - slurm script to collect the results, expects results to be in the folder phylomad_assessment, adjust the script otherwise
* phylomad_collect_array.sh - in case of large dataset, use this array script to collect the results instead, and then concatenate array results.

### Taxon composition
This step counts number of taxa in each group as defined for the filter by taxa step. See **misc**
* taxon_composition_slurm.sh - slurm script to run

## Assess the phylogenetic signal

### Obtain the trees to score

### Run IQ-TREE
This step runs several assessments using IQ-TREE and several custom scripts. See **iqtree** folder
* iqtree_prep.sh - slurm script to run: sets up the folders, lists of files to process and produces the command to run after; adjust paths on lines 9-12 as well as the number of simultaneous jobs on line 20 as needed.
* iqtree_array.sh - slurm script to submit: runs the analyses; **submit using the command output by the previous step in its log file (\*.out)**; adjust paths on lines 16-27 as needed.
* iqtree_array_concat.sh - slurm script to submit: infer concatenation trees
* iqtree_array_gtree.sh - slurm script to submit: infer gene trees
* iqtree_collect_gtrees.sh - slurm script to submit: collect gene tree data
* iqtree_collect_output.sh - slurm script to submit: collect individual fit assessment data
* iqtree_collect_phyloinference_LnL.sh - slurm script to submit: collect concatenation fit assessment data
* trimTrees.R - script to trim taxa off of the main tree(s) depending on the taxon composition of a particular alignment, run by the previous shell script.
* getSCF.R - script to extract sCF values for the branch of interest from IQ-TREE output, run by the previous shell script.

### Run SVDQuartets

TBA
